#
# This file is autogenerated by pip-compile with Python 3.9
# by the following command:
#
#    pip-compile --output-file=gpu-requirements.txt requirements/gpu-requirements.in
#
--extra-index-url https://download.pytorch.org/whl/cu113

aiohttp==3.9.5
    # via openai
aiosignal==1.3.1
    # via aiohttp
annotated-types==0.7.0
    # via pydantic
anyio==4.4.0
    # via
    #   -r requirements/torch-cuda-requirements.txt
    #   httpx
    #   starlette
async-timeout==4.0.3
    # via aiohttp
attrs==23.2.0
    # via aiohttp
blis==0.7.11
    # via thinc
boto3==1.25.0
    # via -r requirements/torch-cuda-requirements.txt
botocore==1.28.5
    # via
    #   -r requirements/torch-cuda-requirements.txt
    #   boto3
    #   s3transfer
catalogue==2.0.10
    # via
    #   spacy
    #   srsly
    #   thinc
certifi==2024.6.2
    # via
    #   -r requirements/torch-cuda-requirements.txt
    #   httpcore
    #   httpx
    #   minio
    #   requests
charset-normalizer==3.3.2
    # via
    #   -r requirements/torch-cuda-requirements.txt
    #   requests
click==8.1.7
    # via
    #   -r requirements/torch-cuda-requirements.txt
    #   typer
    #   uvicorn
cloudpathlib==0.18.1
    # via weasel
cohere==5.3.5
    # via embedders
confection==0.1.5
    # via
    #   thinc
    #   weasel
cymem==2.0.8
    # via
    #   preshed
    #   spacy
    #   thinc
embedders==0.1.8
    # via -r requirements/gpu-requirements.in
exceptiongroup==1.2.1
    # via
    #   -r requirements/torch-cuda-requirements.txt
    #   anyio
fastapi==0.110.3
    # via -r requirements/torch-cuda-requirements.txt
fastavro==1.9.4
    # via cohere
filelock==3.14.0
    # via
    #   -r requirements/torch-cuda-requirements.txt
    #   huggingface-hub
    #   torch
    #   transformers
frozenlist==1.4.1
    # via
    #   aiohttp
    #   aiosignal
fsspec==2024.6.0
    # via
    #   -r requirements/torch-cuda-requirements.txt
    #   huggingface-hub
    #   torch
h11==0.14.0
    # via
    #   -r requirements/torch-cuda-requirements.txt
    #   httpcore
    #   uvicorn
httpcore==1.0.5
    # via httpx
httpx==0.27.0
    # via cohere
httpx-sse==0.4.0
    # via cohere
huggingface-hub==0.23.2
    # via
    #   -r requirements/torch-cuda-requirements.txt
    #   sentence-transformers
    #   tokenizers
    #   transformers
idna==3.7
    # via
    #   -r requirements/torch-cuda-requirements.txt
    #   anyio
    #   httpx
    #   requests
    #   yarl
jinja2==3.1.4
    # via
    #   spacy
    #   torch
jmespath==1.0.1
    # via
    #   -r requirements/torch-cuda-requirements.txt
    #   boto3
    #   botocore
joblib==1.4.2
    # via
    #   -r requirements/torch-cuda-requirements.txt
    #   scikit-learn
    #   scikit-optimize
langcodes==3.4.0
    # via spacy
language-data==1.2.0
    # via langcodes
marisa-trie==1.2.0
    # via language-data
markdown-it-py==3.0.0
    # via rich
markupsafe==2.1.5
    # via jinja2
mdurl==0.1.2
    # via markdown-it-py
minio==7.1.12
    # via -r requirements/torch-cuda-requirements.txt
mpmath==1.3.0
    # via sympy
multidict==6.0.5
    # via
    #   aiohttp
    #   yarl
murmurhash==1.0.10
    # via
    #   preshed
    #   spacy
    #   thinc
networkx==3.2.1
    # via torch
numpy==1.23.4
    # via
    #   -r requirements/torch-cuda-requirements.txt
    #   blis
    #   embedders
    #   pandas
    #   scikit-learn
    #   scikit-optimize
    #   scipy
    #   sentence-transformers
    #   spacy
    #   thinc
    #   torchvision
    #   transformers
openai==0.28.1
    # via
    #   -r requirements/gpu-requirements.in
    #   embedders
packaging==24.0
    # via
    #   -r requirements/torch-cuda-requirements.txt
    #   huggingface-hub
    #   spacy
    #   thinc
    #   transformers
    #   weasel
pandas==1.5.1
    # via -r requirements/torch-cuda-requirements.txt
pillow==10.3.0
    # via
    #   sentence-transformers
    #   torchvision
preshed==3.0.9
    # via
    #   spacy
    #   thinc
psycopg2-binary==2.9.9
    # via -r requirements/torch-cuda-requirements.txt
pyaml==24.4.0
    # via
    #   -r requirements/torch-cuda-requirements.txt
    #   scikit-optimize
pydantic==2.7.4
    # via
    #   -r requirements/gpu-requirements.in
    #   cohere
    #   confection
    #   fastapi
    #   spacy
    #   thinc
    #   weasel
pydantic-core==2.18.4
    # via pydantic
pygments==2.18.0
    # via rich
python-dateutil==2.9.0.post0
    # via
    #   -r requirements/torch-cuda-requirements.txt
    #   botocore
    #   pandas
pytz==2024.1
    # via
    #   -r requirements/torch-cuda-requirements.txt
    #   pandas
pyyaml==6.0.1
    # via
    #   -r requirements/torch-cuda-requirements.txt
    #   huggingface-hub
    #   pyaml
    #   transformers
regex==2024.5.15
    # via
    #   -r requirements/torch-cuda-requirements.txt
    #   transformers
requests==2.31.0
    # via
    #   -r requirements/torch-cuda-requirements.txt
    #   cohere
    #   huggingface-hub
    #   openai
    #   spacy
    #   torchvision
    #   transformers
    #   weasel
rich==13.7.1
    # via typer
s3transfer==0.6.2
    # via
    #   -r requirements/torch-cuda-requirements.txt
    #   boto3
safetensors==0.4.3
    # via
    #   -r requirements/torch-cuda-requirements.txt
    #   transformers
scikit-learn==1.1.2
    # via
    #   -r requirements/torch-cuda-requirements.txt
    #   embedders
    #   scikit-optimize
    #   sentence-transformers
scikit-optimize==0.9.0
    # via -r requirements/torch-cuda-requirements.txt
scipy==1.13.1
    # via
    #   -r requirements/torch-cuda-requirements.txt
    #   scikit-learn
    #   scikit-optimize
    #   sentence-transformers
sentence-transformers==3.0.1
    # via embedders
shellingham==1.5.4
    # via typer
six==1.16.0
    # via
    #   -r requirements/torch-cuda-requirements.txt
    #   python-dateutil
smart-open==7.0.4
    # via weasel
sniffio==1.3.1
    # via
    #   -r requirements/torch-cuda-requirements.txt
    #   anyio
    #   httpx
spacy==3.7.5
    # via
    #   -r requirements/gpu-requirements.in
    #   embedders
spacy-legacy==3.0.12
    # via spacy
spacy-loggers==1.0.5
    # via spacy
sqlalchemy==1.4.42
    # via -r requirements/torch-cuda-requirements.txt
srsly==2.4.8
    # via
    #   confection
    #   spacy
    #   thinc
    #   weasel
starlette==0.37.2
    # via
    #   -r requirements/torch-cuda-requirements.txt
    #   fastapi
sympy==1.13.2
    # via torch
thinc==8.2.5
    # via spacy
threadpoolctl==3.5.0
    # via
    #   -r requirements/torch-cuda-requirements.txt
    #   scikit-learn
tokenizers==0.19.1
    # via
    #   -r requirements/torch-cuda-requirements.txt
    #   cohere
    #   transformers
torch==2.2.0
    # via
    #   -r requirements/torch-cuda-requirements.txt
    #   embedders
    #   sentence-transformers
    #   torchvision
torchvision==0.14.1
    # via -r requirements/gpu-requirements.in
tqdm==4.66.4
    # via
    #   -r requirements/torch-cuda-requirements.txt
    #   embedders
    #   huggingface-hub
    #   openai
    #   sentence-transformers
    #   spacy
    #   transformers
transformers==4.41.2
    # via
    #   -r requirements/torch-cuda-requirements.txt
    #   embedders
    #   sentence-transformers
typer==0.12.3
    # via
    #   spacy
    #   weasel
types-requests==2.31.0.6
    # via cohere
types-urllib3==1.26.25.14
    # via types-requests
typing-extensions==4.12.1
    # via
    #   -r requirements/torch-cuda-requirements.txt
    #   anyio
    #   cloudpathlib
    #   cohere
    #   fastapi
    #   huggingface-hub
    #   pydantic
    #   pydantic-core
    #   starlette
    #   torch
    #   torchvision
    #   typer
urllib3==1.26.18
    # via
    #   -r requirements/torch-cuda-requirements.txt
    #   botocore
    #   minio
    #   requests
uvicorn==0.22.0
    # via -r requirements/torch-cuda-requirements.txt
wasabi==1.1.3
    # via
    #   spacy
    #   thinc
    #   weasel
weasel==0.4.1
    # via spacy
wrapt==1.16.0
    # via smart-open
yarl==1.9.4
    # via aiohttp

# The following packages are considered to be unsafe in a requirements file:
# setuptools
